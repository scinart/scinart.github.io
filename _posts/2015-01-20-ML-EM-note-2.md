---
layout: post
title: "EM 学习 (2)"
date: 2015-01-20
timestamp: "2015-01-20 17:38:28 scinart"
categories: cs
tag: ml
comments: true
toc:
cc: "by-nc-nd"

---

## EM 公式推导

EM算法，基本上看cs229的公开课应该能看懂。

参考1: [从最大似然到 EM 算法浅解](http://blog.csdn.net/zouxy09/article/details/8537620)  
参考2: <http://blog.csdn.net/abcjennifer/article/details/8170378>  
参考3: <http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006936.html>  

本文只负责推公式，基本上和参考2是一样的。

$$
\begin{align}

l(θ) 
&= \sum_{i=1}^{m}{log{p(\mathbf{x}^{(i)}; θ)}} \;\;\;\; & \text{对数极大似然} \\
&= \sum_{i=1}^{m}{log{\sum_{\mathbf{z}^{(i)}}{p(\mathbf{x}^{(i)}, \mathbf{z}^{(i)}; θ)}}}
  & \text{找到}\mathbf{x}\text{背后的latent var }\mathbf{z}^{(i)}\\
&= \sum_{i=1}^{m}{log{\sum_{\mathbf{z}^{(i)}}{Q_{i}(\mathbf{z}^{(i)})\frac{p(\mathbf{x}^{(i)}, \mathbf{z}^{(i)}; θ)}{Q_{i}(\mathbf{z}^{(i)})}}}}
  & \text{强行插入}\mathbf{z}\text{的一个分布形成概率} \\
&= \sum_{i=1}^{m}{log{\underset{\mathbf{z}^{(i)}\sim Q_{i}}{E}\left[ \frac{p(\mathbf{x}^{(i)}, \mathbf{z}^{(i)}; θ)}{Q_{i}(\mathbf{z}^{(i)})} \right]}}
  & \text{将}\frac{p(\mathbf{x}^{(i)}, \mathbf{z}^{(i)}; θ)}{Q_{i}(\mathbf{z}^{(i)})}\text{看成}\mathbf{z}^{(i)}\text{的函数，想像成随机变量}\mathbf{X}\\
&≥ \sum_{i=1}^{m}{\underset{\mathbf{z}^{(i)}\sim Q_{i}}{E}\left[log \frac{p(\mathbf{x}^{(i)}, \mathbf{z}^{(i)}; θ)}{Q_{i}(\mathbf{z}^{(i)})} \right]}
  & log(E[\mathbf{X}]) ≥ E[log(\mathbf{X})]，\text{等号成立 iff } p(\mathbf{X}=E[\mathbf{X}]=1) \\
&= \sum_{i=1}^{m}{\sum_{\mathbf{z}^{(i)}}{Q_{i}(\mathbf{z}^{(i)}) log \frac{p(\mathbf{x}^{(i)}, \mathbf{z}^{(i)}; θ)}{Q_{i}(\mathbf{z}^{(i)})}}}
  &  \text{利用期望的公式得到}
\end{align}
$$

等号成立时，只有我们把那个中间的$$\mathbf{X}$$设成常量。则有

$$
\left\{
\begin{array}{l}
Q_{i}{(\mathbf{z}^{i})} \propto p(\mathbf{x}^{(i)}, \mathbf{z}^{(i)}; θ) \\
\sum_{\mathbf{z}^{(i)}}{Q_{i}{(\mathbf{z}^{i})}} = 1
\end{array}
\right.
$$

小推一下：

$$
Q_{i}(\mathbf{z}^{(i)}) = p(\mathbf{z}^{(i)} | \mathbf{x}^{(i)}; θ)
$$

